{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "606q4MQJZz2U"
   },
   "source": [
    "# Model Selection for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp1ELm57Zz2a"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1725951345762,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "HDmggAMy91S3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## adapt this directory to your needs\n",
    "base_dir = '../'\n",
    "notebook_dir = os.path.join(base_dir, 'Exercise')\n",
    "data_dir = os.path.join(base_dir, 'DataSets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 4639,
     "status": "ok",
     "timestamp": 1725951415531,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "vXCty5i0Zz2b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pyMLaux import show_img_data, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c9KhDatZz2o"
   },
   "source": [
    "## Load Simple Digit Recognition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1725951420044,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "D6TPTi1qZz2o"
   },
   "outputs": [],
   "source": [
    "dig_train_raw = pd.read_csv(os.path.join(data_dir,'Digits_training.csv'), sep=',')\n",
    "dig_train = {'data': np.array(dig_train_raw.iloc[:, :-1]),\n",
    "             'target': np.array(dig_train_raw.iloc[:, -1]),\n",
    "             'feature_names': dig_train_raw.columns[:-1],\n",
    "             'target_names': [str(i) for i in range(0, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1725951422830,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "NMbX-NupZz2p"
   },
   "outputs": [],
   "source": [
    "dig_test_raw = pd.read_csv(os.path.join(data_dir, 'Digits_test.csv'), sep=',')\n",
    "dig_test = {'data': np.array(dig_test_raw.iloc[:, :-1]),\n",
    "            'target': np.array(dig_test_raw.iloc[:, -1]),\n",
    "            'feature_names': dig_test_raw.columns[:-1],\n",
    "            'target_names': [str(i) for i in range(0, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 1815,
     "status": "ok",
     "timestamp": 1725951429065,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "Hdd_vh4uZz2p",
    "outputId": "ea81ce17-4482-43c6-c55e-59d18eefb224"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img_data(dig_train['data'].reshape((dig_train['data'].shape[0], 6, 4, 1)), figsize=(4, 4),\n",
    "              interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1725951432720,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "IUlRxKWRZz2p",
    "outputId": "47986ef0-cacb-472a-dae2-850356003f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 1, 0, 6, 0],\n",
       "       [3, 2, 3, 4, 9, 5],\n",
       "       [3, 3, 1, 6, 4, 7],\n",
       "       [5, 0, 1, 0, 2, 0],\n",
       "       [2, 6, 5, 2, 7, 2]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dig_train['target'][range(0, 30)].reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1725951435412,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "lzYOx6rycIdF"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(dig_train['data'], dig_train['target'],\n",
    "                                                  test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIRr1M4iZz2r"
   },
   "source": [
    "## Functions for Hyperparameter/Architecture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1725951441732,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "YJd7EuX0bLSG"
   },
   "outputs": [],
   "source": [
    "def create_hyperparams(n, default_lr=0.001):\n",
    "    df = pd.DataFrame(index=range(n),\n",
    "                      columns=['no_hidden_layers', 'hidden_layers', 'activation', 'dropout', 'lr', 'epochs'])\n",
    "\n",
    "    for i in range(n):\n",
    "        df.loc[i, 'lr'] = default_lr * 5.**random.uniform(-1., 1.)\n",
    "        df.loc[i, 'epochs'] = random.sample([64, 128, 256], 1)[0] # Removed 16 and 32 epochs ==> too few epochs. Also added 256\n",
    "\n",
    "        no_layers = random.randint(2, 8) # Zero and 1 hidden layers make no sense. Also increase to 8 hidden layers instead of 4\n",
    "        df.loc[i, 'no_hidden_layers'] = no_layers\n",
    "\n",
    "        # Number of neuron in hidden layers: Remove random sampling, because it makes no sense if neuron counts are random ==> implement a decreasing pattern\n",
    "        # This value is only the initial value\n",
    "        # Create decreasing layer sizes\n",
    "        initial_size = random.sample([784, 392], 1)[0]  # Start large to capture all information ( 28x28 = 784 pixels or 28x14 = 392 pixels)\n",
    "        layer_sizes = [initial_size]\n",
    "        \n",
    "        # Calculate reduction factor\n",
    "        reduction = (initial_size / 32) ** (1.0 / (no_layers - 1))\n",
    "        \n",
    "        # Generate remaining layers with smooth size reduction\n",
    "        current_size = initial_size\n",
    "        for _ in range(no_layers - 1):\n",
    "            current_size = int(current_size / reduction)\n",
    "            current_size = max(32, min(current_size, layer_sizes[-1]))  # Ensure smooth decrease\n",
    "            layer_sizes.append(current_size)\n",
    "            \n",
    "        df.loc[i, 'hidden_layers'] = layer_sizes\n",
    "\n",
    "        # df.loc[i, 'hidden_layers'] = [int(random.sample([32, 64, 128, 256, 512], 1)[0]) for i in range(no_layers)] # \n",
    "        df.loc[i, 'dropout'] = random.sample([0.2, 0.3, 0.4, 0.5], 1)[0] # Removed 0 dropout, because it is not recommended for deep networks\n",
    "        df.loc[i, 'activation'] = random.sample(['relu', 'elu'], 1)[0] # Removed sigmoid, because it does not train well for deep networks\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1725951444068,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "fFtzoyAFbaTf"
   },
   "outputs": [],
   "source": [
    "def create_network(hp, no_inputs, no_outputs, output_activation='softmax', **kwargs):\n",
    "    hidden_layers = hp['hidden_layers']\n",
    "\n",
    "    dropout = hp['dropout']\n",
    "    hidden_activation = hp['activation']\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(no_inputs, )))\n",
    "\n",
    "    for cl in hidden_layers:\n",
    "        model.add(tf.keras.layers.Dense(cl, activation=hidden_activation))\n",
    "        if dropout > 0:\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(no_outputs, activation=output_activation))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=hp['lr'])\n",
    "\n",
    "    model.compile(optimizer=opt, **kwargs)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1725951447574,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "3qoRsDnIyhQ-",
    "outputId": "6c864419-8dbc-4472-d235-b97bb5781ac1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[392, 112, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[784, 496, 314, 198, 125, 79, 50, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[784, 158, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[392, 209, 111, 59, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[392, 112, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[392, 209, 111, 59, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>[392, 112, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>[392, 274, 191, 133, 92, 64, 44, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>[392, 209, 111, 59, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>[392, 170, 73, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  no_hidden_layers                          hidden_layers activation dropout  \\\n",
       "0                3                         [392, 112, 32]       relu     0.2   \n",
       "1                8  [784, 496, 314, 198, 125, 79, 50, 32]       relu     0.2   \n",
       "2                3                         [784, 158, 32]        elu     0.2   \n",
       "3                5                [392, 209, 111, 59, 32]        elu     0.4   \n",
       "4                3                         [392, 112, 32]        elu     0.2   \n",
       "5                5                [392, 209, 111, 59, 32]       relu     0.3   \n",
       "6                3                         [392, 112, 32]       relu     0.4   \n",
       "7                8   [392, 274, 191, 133, 92, 64, 44, 32]       relu     0.2   \n",
       "8                5                [392, 209, 111, 59, 32]       relu     0.2   \n",
       "9                4                     [392, 170, 73, 32]        elu     0.2   \n",
       "\n",
       "         lr epochs  \n",
       "0  0.000458    256  \n",
       "1  0.000205     64  \n",
       "2  0.000531    256  \n",
       "3  0.001031    256  \n",
       "4  0.004761    256  \n",
       "5  0.004237    256  \n",
       "6  0.002063     64  \n",
       "7  0.001437    256  \n",
       "8  0.000457    128  \n",
       "9  0.000755     64  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_hyperparams(10) # Create 1000000 hyperparameters to search through\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1725951453572,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "3EoJWf0Obfe1"
   },
   "outputs": [],
   "source": [
    "model = create_network(df.iloc[1, :], no_inputs=24, no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1725951455805,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "2hYyghEmbiTQ",
    "outputId": "9887751a-eb2c-4a17-b3fc-53381ba39203"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">389,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">314</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">156,058</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">314</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,370</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,875</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,954</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │        \u001b[38;5;34m19,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m)            │       \u001b[38;5;34m389,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m496\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m314\u001b[0m)            │       \u001b[38;5;34m156,058\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m314\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m)            │        \u001b[38;5;34m62,370\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m)            │        \u001b[38;5;34m24,875\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m)             │         \u001b[38;5;34m9,954\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m4,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">668,179</span> (2.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m668,179\u001b[0m (2.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">668,179</span> (2.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m668,179\u001b[0m (2.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1725951459383,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "KxQzPx_-bpl9"
   },
   "outputs": [],
   "source": [
    "def find_best(df, crit='ACC'):\n",
    "    index = np.where(df[crit] == np.amax(df[crit]))[0]\n",
    "    return(df.iloc[list(index), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2zsFjuDbrDW"
   },
   "source": [
    "## Perform Model Selection and Determine Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1725951469355,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "D0tU9QQKbvb8"
   },
   "outputs": [],
   "source": [
    "random.seed(4232)\n",
    "batch_size = 32\n",
    "no_models = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1725951471887,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "0_CsQAjUbzws"
   },
   "outputs": [],
   "source": [
    "model_sel = create_hyperparams(no_models)\n",
    "model_sel['ACC'] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1725951474358,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "W7CmdoUuzMvD",
    "outputId": "3aecc9f9-9769-4bb8-9216-bc048c546691"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[784, 352, 158, 71, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>[784, 496, 314, 198, 125, 79, 50, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[392, 237, 143, 86, 52, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[392, 237, 143, 86, 52, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[392, 170, 73, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>3</td>\n",
       "      <td>[392, 112, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>6</td>\n",
       "      <td>[784, 413, 217, 114, 60, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>2</td>\n",
       "      <td>[392, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>2</td>\n",
       "      <td>[392, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>3</td>\n",
       "      <td>[784, 158, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no_hidden_layers                          hidden_layers activation  \\\n",
       "0                   5                [784, 352, 158, 71, 32]       relu   \n",
       "1                   8  [784, 496, 314, 198, 125, 79, 50, 32]       relu   \n",
       "2                   6            [392, 237, 143, 86, 52, 32]        elu   \n",
       "3                   6            [392, 237, 143, 86, 52, 32]       relu   \n",
       "4                   4                     [392, 170, 73, 32]        elu   \n",
       "...               ...                                    ...        ...   \n",
       "1495                3                         [392, 112, 32]        elu   \n",
       "1496                6           [784, 413, 217, 114, 60, 32]        elu   \n",
       "1497                2                              [392, 32]        elu   \n",
       "1498                2                              [392, 32]        elu   \n",
       "1499                3                         [784, 158, 32]       relu   \n",
       "\n",
       "     dropout        lr epochs  ACC  \n",
       "0        0.3  0.000845    128 -1.0  \n",
       "1        0.5  0.003878     64 -1.0  \n",
       "2        0.5  0.000339     64 -1.0  \n",
       "3        0.5  0.000638    128 -1.0  \n",
       "4        0.3  0.002231    128 -1.0  \n",
       "...      ...       ...    ...  ...  \n",
       "1495     0.4  0.001683     64 -1.0  \n",
       "1496     0.4  0.000288     64 -1.0  \n",
       "1497     0.3  0.000661    128 -1.0  \n",
       "1498     0.2  0.002178    128 -1.0  \n",
       "1499     0.2  0.000351    256 -1.0  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413258,
     "status": "ok",
     "timestamp": 1725951898844,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "mPYnYCYKb2Ug",
    "outputId": "fc5910bd-a6d6-46fd-b66e-affbfe56c149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60815s\u001b[0m 41s/step\n"
     ]
    }
   ],
   "source": [
    "pbar = tf.keras.utils.Progbar(target=no_models, stateful_metrics=[]) ## progress bar\n",
    "for i in range(no_models):\n",
    "    model = create_network(model_sel.iloc[i], no_inputs=X_train.shape[1],\n",
    "                           no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x=X_train, y=y_train,\n",
    "                        epochs=model_sel['epochs'][i],\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "\n",
    "    pred = model.predict(x=X_val, verbose=0)\n",
    "    predC = np.argmax(pred, axis=1)\n",
    "\n",
    "    model_sel.loc[i, 'ACC'] = accuracy_score(y_val, predC)\n",
    "\n",
    "    # Use the modern API to clear th model\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    pbar.update(i, finalize=False)\n",
    "pbar.update(no_models, finalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1725951938286,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "jo0QXrbPnK_N",
    "outputId": "a1fb369c-0533-446e-e169-3a12a4b1073d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>[784, 158, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>256</td>\n",
       "      <td>0.962222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>3</td>\n",
       "      <td>[392, 112, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>256</td>\n",
       "      <td>0.961111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4</td>\n",
       "      <td>[392, 170, 73, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>256</td>\n",
       "      <td>0.961111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>7</td>\n",
       "      <td>[392, 258, 169, 111, 73, 48, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>2</td>\n",
       "      <td>[784, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>2</td>\n",
       "      <td>[784, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2</td>\n",
       "      <td>[784, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>128</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>3</td>\n",
       "      <td>[784, 158, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5</td>\n",
       "      <td>[784, 352, 158, 71, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>256</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2</td>\n",
       "      <td>[784, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>256</td>\n",
       "      <td>0.958889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     no_hidden_layers                     hidden_layers activation dropout  \\\n",
       "176                 3                    [784, 158, 32]       relu     0.2   \n",
       "277                 3                    [392, 112, 32]       relu     0.2   \n",
       "488                 4                [392, 170, 73, 32]       relu     0.5   \n",
       "683                 7  [392, 258, 169, 111, 73, 48, 32]       relu     0.3   \n",
       "961                 2                         [784, 32]       relu     0.5   \n",
       "1194                2                         [784, 32]       relu     0.2   \n",
       "270                 2                         [784, 32]       relu     0.2   \n",
       "977                 3                    [784, 158, 32]        elu     0.2   \n",
       "197                 5           [784, 352, 158, 71, 32]       relu     0.4   \n",
       "743                 2                         [784, 32]       relu     0.2   \n",
       "\n",
       "            lr epochs       ACC  \n",
       "176   0.002085    256  0.962222  \n",
       "277   0.000406    256  0.961111  \n",
       "488    0.00042    256  0.961111  \n",
       "683   0.000445    256  0.960000  \n",
       "961   0.001539    256  0.960000  \n",
       "1194   0.00054    256  0.960000  \n",
       "270   0.000555    128  0.960000  \n",
       "977   0.000826    256  0.960000  \n",
       "197   0.001514    256  0.960000  \n",
       "743   0.000596    256  0.958889  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.sort_values(by='ACC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1725951941761,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "oKRrMA27ciRn",
    "outputId": "874a977d-3ae1-445c-cb1a-6309d12deb79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>[784, 158, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>256</td>\n",
       "      <td>0.962222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_hidden_layers   hidden_layers activation dropout        lr epochs  \\\n",
       "176                3  [784, 158, 32]       relu     0.2  0.002085    256   \n",
       "\n",
       "          ACC  \n",
       "176  0.962222  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best(model_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1725951945175,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "W7C3g4pHcG67"
   },
   "outputs": [],
   "source": [
    "best_index = find_best(model_sel).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3gGoxx4cldW"
   },
   "source": [
    "## Train Model on Entire Training Set Using Best Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1725951948024,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "dHrP42SjcoGa"
   },
   "outputs": [],
   "source": [
    "model = create_network(model_sel.loc[best_index], no_inputs=X_train.shape[1],\n",
    "                       no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1725951950325,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "GevKGfVpcqUe",
    "outputId": "72696c2a-4ae3-488a-93ac-dfda5326b50d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,030</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">158</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │        \u001b[38;5;34m19,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m)            │       \u001b[38;5;34m124,030\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m158\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m5,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,048</span> (582.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m149,048\u001b[0m (582.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,048</span> (582.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,048\u001b[0m (582.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6459,
     "status": "ok",
     "timestamp": 1725951969662,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "8SOr03A1ctap",
    "outputId": "c02a721c-e9f5-486e-c7b3-5557ec6cb564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3630 - loss: 1.8255\n",
      "Epoch 2/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7267 - loss: 0.8552\n",
      "Epoch 3/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.6220\n",
      "Epoch 4/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8438 - loss: 0.5221\n",
      "Epoch 5/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.4629\n",
      "Epoch 6/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.4381\n",
      "Epoch 7/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3402\n",
      "Epoch 8/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.3358\n",
      "Epoch 9/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3424\n",
      "Epoch 10/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2940\n",
      "Epoch 11/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2750\n",
      "Epoch 12/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2525\n",
      "Epoch 13/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2630\n",
      "Epoch 14/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2502\n",
      "Epoch 15/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2380\n",
      "Epoch 16/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2369\n",
      "Epoch 17/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9315 - loss: 0.2167\n",
      "Epoch 18/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2085\n",
      "Epoch 19/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.1849\n",
      "Epoch 20/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1899\n",
      "Epoch 21/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1918\n",
      "Epoch 22/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1730\n",
      "Epoch 23/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1727\n",
      "Epoch 24/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1416\n",
      "Epoch 25/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1365\n",
      "Epoch 26/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1678\n",
      "Epoch 27/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1547\n",
      "Epoch 28/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1195\n",
      "Epoch 29/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1436\n",
      "Epoch 30/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9567 - loss: 0.1285\n",
      "Epoch 31/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1176\n",
      "Epoch 32/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9546 - loss: 0.1428\n",
      "Epoch 33/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1213\n",
      "Epoch 34/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9621 - loss: 0.1232\n",
      "Epoch 35/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1208\n",
      "Epoch 36/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1342\n",
      "Epoch 37/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9578 - loss: 0.1275\n",
      "Epoch 38/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0897\n",
      "Epoch 39/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.1421\n",
      "Epoch 40/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0979\n",
      "Epoch 41/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1015\n",
      "Epoch 42/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1036\n",
      "Epoch 43/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.1088\n",
      "Epoch 44/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0931\n",
      "Epoch 45/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1133\n",
      "Epoch 46/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9641 - loss: 0.1101\n",
      "Epoch 47/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9670 - loss: 0.1013\n",
      "Epoch 48/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.0929\n",
      "Epoch 49/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0981\n",
      "Epoch 50/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0911\n",
      "Epoch 51/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.0985\n",
      "Epoch 52/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0761\n",
      "Epoch 53/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.0875\n",
      "Epoch 54/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.1069\n",
      "Epoch 55/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0785\n",
      "Epoch 56/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0702\n",
      "Epoch 57/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.1125\n",
      "Epoch 58/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0971\n",
      "Epoch 59/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9707 - loss: 0.0860\n",
      "Epoch 60/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.0909\n",
      "Epoch 61/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.0701\n",
      "Epoch 62/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9673 - loss: 0.0975\n",
      "Epoch 63/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0884\n",
      "Epoch 64/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0809\n",
      "Epoch 65/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0993\n",
      "Epoch 66/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0668\n",
      "Epoch 67/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9731 - loss: 0.0825\n",
      "Epoch 68/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0962\n",
      "Epoch 69/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0489\n",
      "Epoch 70/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0470\n",
      "Epoch 71/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1136\n",
      "Epoch 72/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.1008\n",
      "Epoch 73/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0720\n",
      "Epoch 74/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0768\n",
      "Epoch 75/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.0656\n",
      "Epoch 76/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.0808\n",
      "Epoch 77/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0718\n",
      "Epoch 78/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0653\n",
      "Epoch 79/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0727\n",
      "Epoch 80/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.0949\n",
      "Epoch 81/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0666\n",
      "Epoch 82/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0479\n",
      "Epoch 83/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0487\n",
      "Epoch 84/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9732 - loss: 0.0804\n",
      "Epoch 85/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0613\n",
      "Epoch 86/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.0481\n",
      "Epoch 87/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0641\n",
      "Epoch 88/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1003\n",
      "Epoch 89/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0403\n",
      "Epoch 90/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0523\n",
      "Epoch 91/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0739\n",
      "Epoch 92/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0690\n",
      "Epoch 93/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0613\n",
      "Epoch 94/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0532\n",
      "Epoch 95/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0776\n",
      "Epoch 96/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0714\n",
      "Epoch 97/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0861\n",
      "Epoch 98/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0432\n",
      "Epoch 99/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0572\n",
      "Epoch 100/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0499\n",
      "Epoch 101/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0652\n",
      "Epoch 102/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0419\n",
      "Epoch 103/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0847\n",
      "Epoch 104/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.0769\n",
      "Epoch 105/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.0511\n",
      "Epoch 106/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0550\n",
      "Epoch 107/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0627\n",
      "Epoch 108/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0540\n",
      "Epoch 109/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.0814\n",
      "Epoch 110/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0560\n",
      "Epoch 111/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0475\n",
      "Epoch 112/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0434\n",
      "Epoch 113/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0424\n",
      "Epoch 114/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0403\n",
      "Epoch 115/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0468\n",
      "Epoch 116/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0612\n",
      "Epoch 117/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.0725\n",
      "Epoch 118/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0871\n",
      "Epoch 119/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0619\n",
      "Epoch 120/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0377\n",
      "Epoch 121/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0524\n",
      "Epoch 122/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9923 - loss: 0.0271\n",
      "Epoch 123/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0272\n",
      "Epoch 124/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.1131\n",
      "Epoch 125/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0639\n",
      "Epoch 126/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0454\n",
      "Epoch 127/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0532\n",
      "Epoch 128/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0574\n",
      "Epoch 129/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0467\n",
      "Epoch 130/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0306\n",
      "Epoch 131/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0412\n",
      "Epoch 132/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0545\n",
      "Epoch 133/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0350\n",
      "Epoch 134/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0610\n",
      "Epoch 135/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9747 - loss: 0.0816\n",
      "Epoch 136/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0839\n",
      "Epoch 137/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0513\n",
      "Epoch 138/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0458\n",
      "Epoch 139/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0509\n",
      "Epoch 140/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.0444\n",
      "Epoch 141/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0694\n",
      "Epoch 142/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0565\n",
      "Epoch 143/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0726\n",
      "Epoch 144/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0467\n",
      "Epoch 145/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0498\n",
      "Epoch 146/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0332\n",
      "Epoch 147/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0320\n",
      "Epoch 148/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0394\n",
      "Epoch 149/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9933 - loss: 0.0265\n",
      "Epoch 150/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0303\n",
      "Epoch 151/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0351\n",
      "Epoch 152/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0443\n",
      "Epoch 153/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0378\n",
      "Epoch 154/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0342\n",
      "Epoch 155/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.0587\n",
      "Epoch 156/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0952\n",
      "Epoch 157/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0640\n",
      "Epoch 158/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.0529\n",
      "Epoch 159/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0526\n",
      "Epoch 160/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0339\n",
      "Epoch 161/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0416\n",
      "Epoch 162/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9936 - loss: 0.0222\n",
      "Epoch 163/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0560\n",
      "Epoch 164/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0361\n",
      "Epoch 165/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0464\n",
      "Epoch 166/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0828\n",
      "Epoch 167/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0536\n",
      "Epoch 168/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0449\n",
      "Epoch 169/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0320\n",
      "Epoch 170/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0340\n",
      "Epoch 171/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0435\n",
      "Epoch 172/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0656\n",
      "Epoch 173/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0522\n",
      "Epoch 174/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0235\n",
      "Epoch 175/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0229\n",
      "Epoch 176/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0310\n",
      "Epoch 177/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0248\n",
      "Epoch 178/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0352\n",
      "Epoch 179/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0263\n",
      "Epoch 180/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0269\n",
      "Epoch 181/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0996\n",
      "Epoch 182/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1021\n",
      "Epoch 183/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0323\n",
      "Epoch 184/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0231\n",
      "Epoch 185/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0460\n",
      "Epoch 186/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0363\n",
      "Epoch 187/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0433\n",
      "Epoch 188/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0344\n",
      "Epoch 189/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0238\n",
      "Epoch 190/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0280\n",
      "Epoch 191/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0232\n",
      "Epoch 192/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0434\n",
      "Epoch 193/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0172\n",
      "Epoch 194/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0133\n",
      "Epoch 195/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0423\n",
      "Epoch 196/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0586\n",
      "Epoch 197/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.0784\n",
      "Epoch 198/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0416\n",
      "Epoch 199/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0225\n",
      "Epoch 200/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9913 - loss: 0.0296\n",
      "Epoch 201/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0550\n",
      "Epoch 202/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.1037\n",
      "Epoch 203/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0610\n",
      "Epoch 204/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0606\n",
      "Epoch 205/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9882 - loss: 0.0342\n",
      "Epoch 206/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0441\n",
      "Epoch 207/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0325\n",
      "Epoch 208/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0243\n",
      "Epoch 209/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0266\n",
      "Epoch 210/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9904 - loss: 0.0320\n",
      "Epoch 211/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0515\n",
      "Epoch 212/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0813\n",
      "Epoch 213/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.0297\n",
      "Epoch 214/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0383\n",
      "Epoch 215/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0451\n",
      "Epoch 216/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0565\n",
      "Epoch 217/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9907 - loss: 0.0385\n",
      "Epoch 218/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0181\n",
      "Epoch 219/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0390\n",
      "Epoch 220/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.0863\n",
      "Epoch 221/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9873 - loss: 0.0393\n",
      "Epoch 222/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9879 - loss: 0.0398\n",
      "Epoch 223/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0636\n",
      "Epoch 224/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0257\n",
      "Epoch 225/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0259\n",
      "Epoch 226/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0231\n",
      "Epoch 227/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 0.0329\n",
      "Epoch 228/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0601\n",
      "Epoch 229/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0437\n",
      "Epoch 230/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0321\n",
      "Epoch 231/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9868 - loss: 0.0476\n",
      "Epoch 232/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0246\n",
      "Epoch 233/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0376\n",
      "Epoch 234/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0088\n",
      "Epoch 235/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0215\n",
      "Epoch 236/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9953 - loss: 0.0162\n",
      "Epoch 237/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0438\n",
      "Epoch 238/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0403\n",
      "Epoch 239/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0317\n",
      "Epoch 240/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0273\n",
      "Epoch 241/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0272\n",
      "Epoch 242/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0721\n",
      "Epoch 243/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0294\n",
      "Epoch 244/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0365\n",
      "Epoch 245/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0497\n",
      "Epoch 246/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0282\n",
      "Epoch 247/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.0402\n",
      "Epoch 248/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0281\n",
      "Epoch 249/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0467\n",
      "Epoch 250/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0401\n",
      "Epoch 251/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0419\n",
      "Epoch 252/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.0352\n",
      "Epoch 253/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0224\n",
      "Epoch 254/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0211\n",
      "Epoch 255/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.0207\n",
      "Epoch 256/256\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9910 - loss: 0.0275\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=dig_train['data'], y=dig_train['target'],\n",
    "                    epochs=model_sel.loc[best_index, 'epochs'],\n",
    "                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tovQW_Llc1Fw"
   },
   "source": [
    "## Test Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1725951975129,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "5g81CNxUc2Z8",
    "outputId": "3a1f63f5-c109-45ba-8a8d-a0e6bc3df76f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion matrix (rows -> true, columns -> predicted):\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  207    2    0    0    0    0    2    1    0    0\n",
      "1    0  195    0    0    2    0    0    4    0    2\n",
      "2    0    1  181    0    1    0    1    1    0    1\n",
      "3    0    4    1  186    0    4    0    3    0    4\n",
      "4    0    3    0    0  199    0    4    0    0    2\n",
      "5    0    1    0    1    1  178    7    0    0    2\n",
      "6    2    2    0    0    2    1  197    0    0    0\n",
      "7    0    3    0    0    0    0    0  195    1    3\n",
      "8    1    9    0    4    0    1    2    2  171    3\n",
      "9    1    2    2    1    1    3    0    0    1  193\n",
      "\n",
      "\n",
      "Class 0:\n",
      "    Sensitivity (TPR):  97.642% (207 of 212)\n",
      "    Specificity (TNR):  99.777% (1788 of 1792)\n",
      "    Precision:          98.104% (207 of 211)\n",
      "    Neg. pred. value:   99.721% (1788 of 1793)\n",
      "Class 1:\n",
      "    Sensitivity (TPR):  96.059% (195 of 203)\n",
      "    Specificity (TNR):  98.501% (1774 of 1801)\n",
      "    Precision:          87.838% (195 of 222)\n",
      "    Neg. pred. value:   99.551% (1774 of 1782)\n",
      "Class 2:\n",
      "    Sensitivity (TPR):  97.312% (181 of 186)\n",
      "    Specificity (TNR):  99.835% (1815 of 1818)\n",
      "    Precision:          98.370% (181 of 184)\n",
      "    Neg. pred. value:   99.725% (1815 of 1820)\n",
      "Class 3:\n",
      "    Sensitivity (TPR):  92.079% (186 of 202)\n",
      "    Specificity (TNR):  99.667% (1796 of 1802)\n",
      "    Precision:          96.875% (186 of 192)\n",
      "    Neg. pred. value:   99.117% (1796 of 1812)\n",
      "Class 4:\n",
      "    Sensitivity (TPR):  95.673% (199 of 208)\n",
      "    Specificity (TNR):  99.610% (1789 of 1796)\n",
      "    Precision:          96.602% (199 of 206)\n",
      "    Neg. pred. value:   99.499% (1789 of 1798)\n",
      "Class 5:\n",
      "    Sensitivity (TPR):  93.684% (178 of 190)\n",
      "    Specificity (TNR):  99.504% (1805 of 1814)\n",
      "    Precision:          95.187% (178 of 187)\n",
      "    Neg. pred. value:   99.340% (1805 of 1817)\n",
      "Class 6:\n",
      "    Sensitivity (TPR):  96.569% (197 of 204)\n",
      "    Specificity (TNR):  99.111% (1784 of 1800)\n",
      "    Precision:          92.488% (197 of 213)\n",
      "    Neg. pred. value:   99.609% (1784 of 1791)\n",
      "Class 7:\n",
      "    Sensitivity (TPR):  96.535% (195 of 202)\n",
      "    Specificity (TNR):  99.390% (1791 of 1802)\n",
      "    Precision:          94.660% (195 of 206)\n",
      "    Neg. pred. value:   99.611% (1791 of 1798)\n",
      "Class 8:\n",
      "    Sensitivity (TPR):  88.601% (171 of 193)\n",
      "    Specificity (TNR):  99.890% (1809 of 1811)\n",
      "    Precision:          98.844% (171 of 173)\n",
      "    Neg. pred. value:   98.798% (1809 of 1831)\n",
      "Class 9:\n",
      "    Sensitivity (TPR):  94.608% (193 of 204)\n",
      "    Specificity (TNR):  99.056% (1783 of 1800)\n",
      "    Precision:          91.905% (193 of 210)\n",
      "    Neg. pred. value:   99.387% (1783 of 1794)\n",
      "\n",
      "Overall accuracy:   94.910% (1902 of 2004)\n",
      "Balanced accuracy:  94.876%\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(dig_test['data'])\n",
    "\n",
    "evaluate_classification_result(dig_test['target'], pred, classes=dig_test['target_names'])\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(base_dir, 'Ex3_Grimm.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3800,
     "status": "ok",
     "timestamp": 1725952018810,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "qoGk887kBBza",
    "outputId": "d7afbc9a-927d-4a76-b024-8fce1fe3ccf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Ex3_Grimm.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
      "[NbConvertApp] Writing 380205 bytes to Ex3_Grimm.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html Ex3_Grimm.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "NDLeIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
