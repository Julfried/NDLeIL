{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "606q4MQJZz2U"
   },
   "source": [
    "# Model Selection for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp1ELm57Zz2a"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1725951345762,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "HDmggAMy91S3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## adapt this directory to your needs\n",
    "base_dir = '../'\n",
    "notebook_dir = os.path.join(base_dir, 'Exercise')\n",
    "data_dir = os.path.join(base_dir, 'DataSets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 4639,
     "status": "ok",
     "timestamp": 1725951415531,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "vXCty5i0Zz2b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pyMLaux import show_img_data, evaluate_classification_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c9KhDatZz2o"
   },
   "source": [
    "## Load Simple Digit Recognition Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 1413,
     "status": "ok",
     "timestamp": 1725951420044,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "D6TPTi1qZz2o"
   },
   "outputs": [],
   "source": [
    "dig_train_raw = pd.read_csv(os.path.join(data_dir,'Digits_training.csv'), sep=',')\n",
    "dig_train = {'data': np.array(dig_train_raw.iloc[:, :-1]),\n",
    "             'target': np.array(dig_train_raw.iloc[:, -1]),\n",
    "             'feature_names': dig_train_raw.columns[:-1],\n",
    "             'target_names': [str(i) for i in range(0, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1725951422830,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "NMbX-NupZz2p"
   },
   "outputs": [],
   "source": [
    "dig_test_raw = pd.read_csv(os.path.join(data_dir, 'Digits_test.csv'), sep=',')\n",
    "dig_test = {'data': np.array(dig_test_raw.iloc[:, :-1]),\n",
    "            'target': np.array(dig_test_raw.iloc[:, -1]),\n",
    "            'feature_names': dig_test_raw.columns[:-1],\n",
    "            'target_names': [str(i) for i in range(0, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 1815,
     "status": "ok",
     "timestamp": 1725951429065,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "Hdd_vh4uZz2p",
    "outputId": "ea81ce17-4482-43c6-c55e-59d18eefb224"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAFICAYAAADOAUz5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe6ElEQVR4nO3dfXBU5fXA8SeEvJINQgElJXR4HSsUQdRORRAEWiitgmCRYqdFyltFFKZQi7Qw2ADWIlD6Igh2KshLoGp12pkOoBUHRITC8FIppYNhaVARCrubbJJNdn9/+Lu/8ut4z3k2udAkz/czw1/PuWfvyd49XmfPPjcjlUqlDAA4qsV/+wQA4L+JJgjAaTRBAE6jCQJwGk0QgNNoggCcRhME4DSaIACntbQJSiaTpry83IRCIZORkXG1z0mUSqVMNBo1RUVFpkWL+vfwxlSTMcHURU1XX3O8/pyvKWUhHA6njDGN6l84HLY59SZVU0ProqamUVNjrcvVmqzuBEOhkDHGmIMHD5qCggLfuMmTJ6u5Pv74YzXmoYce8l2rqqoyP/7xj//vnOrLO/748eNirrKyMjVXVVWVGtOhQwdxPRaLmQEDBjSoLu/YcDhsCgsLfeMmTpyo5ho+fLga853vfEdcj0Qipri4OJCatm3bZvLz833jRo0apeaaMmWKGlNSUiKuR6NR061bt8CuP+292rBhg5rL5hpdsGCB71oQ75Mx/65p//79Yp/41re+peb6y1/+osasW7fOdy0ej5uZM2da1WTVBL1b24KCAjFpy5Z6uszMTDUmLy/P+pzqyzs+FAqJF6H0ZnpsarK9wBpSl3dsYWGhWFNWVpaay+Y9kF7j086rPrxj8/PzTatWreqdxxhjsrOz1ZhrUdOVx2vvlc37kJOTo8bY1BVUTVqfsPm82JyL9B/FdPLwxQgAp9EEATiNJgjAaTRBAE6jCQJwmtW3w5558+aJ3ywOHjxYzbFw4UI1RvpmKRXwRtj79+8Xv3UcOXKkmmPMmDFqzI9+9CNxPRaLqTmC8vLLL6sxN9xwwzU4E3tLly4Vpw9WrFih5jh27JgaM2PGDHG9pqZGzZGOeDwufqbWrFmj5tDGeq61gQMHigPKEyZMUHM88cQTaszo0aN919LpE9wJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOS2tY+sEHHxS3r3nppZfUHGvXrlVj+vbt67tWW1tr9u3bp+awVVxcLG6XNW7cODVHRUWFGnPu3DlxvbKyUs0RlO7du6sxp06dugZnYu+6664Th4ofe+wxNYfNQLq2j2Jtba2aIx1Hjx4Vh/WPHz+u5mjbtq0aIw0PB/0DhEQiIW5htWrVKjXH2bNn1Rhpe7BUKmUikYiawxjuBAE4jiYIwGk0QQBOowkCcBpNEIDTaIIAnEYTBOA0miAAp6U1LN21a1dxsPj3v/+9mmP9+vVqjDR8HIlETMeOHdUctnr06CEOXW7ZskXN8dprr6kxv/nNb8T1RCKh5ghKp06d1JhwOHwNzsRex44drZ4bLLF5hrR2bQX9Pr399tsmNzfXd91miH7ixIlqzPe+9z3ftXg8rh6fjhYtWjT4GcavvPKKGiP9cCOZTDIsDQA2aIIAnEYTBOA0miAAp9EEATiNJgjAaTRBAE6jCQJwWlrD0t/4xjdMZmam7/qOHTvUHCUlJWrMnj17fNdsdnFOx8WLF8UB2AULFqg5zpw5o8Y8+OCD4no8HrcaNg9C69at1ZjDhw9f/RNJw9GjR03Llv6X64cffqjmePfdd9WY8+fPi+tB7yydnZ0tDoGPHTtWzaFdW8YYM2nSJN+1oHeWvnTpkrh+3333qTlsesnOnTt91yoqKszQoUPVHMZwJwjAcTRBAE6jCQJwGk0QgNNoggCcRhME4DSaIACn0QQBOC2tYekvf/nLJicnx3d9ypQpDT4hY4zp06eP71o0Gg3kNTzt27cXd5Z+6KGH1ByxWEyNufvuu8X1SCRipk6dquYJwr333qvGfPDBB9fgTOz169dPvPbGjRun5sjLy1Njnn76aXG9oqLCDBs2TM1j65577jGhUMh3/ZlnnlFzbN++XY2ZMGGC71oikbDKYesXv/iF+Ld+44031BzvvfeeGiPtkG67q7Qx3AkCcBxNEIDTaIIAnEYTBOA0miAAp9EEATiNJgjAaVZzgt6mizU1NWJcXV1dw8/IyLOA3lpDN4L0jtfmiWw2cbWJ0V7HW29IXbY1xeNxNZfN5qHXsibt2rM5X5sY7b301oO6/rQZ02Qy2aDX8UgbB3trQdWkXV/ae2mM3TywdP2lde2lLITD4ZQxplH9C4fDNqfepGpqaF3U1DRqaqx1uVpTRiqlt8pkMmnKy8tNKBQyGRkZWvhVlUqlTDQaNUVFRaZFi/r/33xjqsmYYOqipquvOV5/rtdk1QQBoLniixEATqMJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4zepnc011CFLSmGoyhsFiP82xJmMaV13O19Scfw7T1GpqaF3U1DRqaqx1uVqT1Z2g9yCYX//61+IDVPbt26fmys/PV2OmT5/uuxaLxcwtt9wiPpzGhnf8ypUrxZqOHTum5rL5Yf4dd9whrsfjcTN16tQG1eUd++KLL4p/55KSknq/xpWWLFkirldUVJgxY8YEUlObNm3Eu4sTJ06ouaQHNXlSyg+oIpGI6dy5c2DX38KFC01ubq5v3MqVK9VcrVq1UmMWL17su1ZZWdnga8+Yf9fUv39/07Klf2uxeQhS69at1ZjbbrvNd62mpsasWbPGqiarJuhdfHl5eeKHy+Yis4mxOfGG3m5fWZPUBG3ONzMzU42xaf5Xnld9eMfm5+eLHwzpAk2HzYfvyvOqD+/YjIwM8X9rpCcGeoJogv95XvXlHZ+bmys2QZv/PbWJsbn+gqqpZcuW4jVm83mxuUZt3k+bmvhiBIDTaIIAnEYTBOA0miAAp9EEATgtra8J77jjDvGb25EjR6o5duzYocZs377dd83m+RjpeO6558RvoiZOnKjmOH/+vBqjjZME9XwWYz4ZQZDGdubNm6fmOHLkiBqza9cucb2qqkrNYSsjI0P8pi+oZ3Fo3yYGPQS8bNkyMeecOXPUHBcvXlRjpPc8qL+dJxQKmaysLN/1tWvXqjluuukmNUb6Jj8SiZjVq1erOYzhThCA42iCAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOowkCcFpaw9LXX3+9uGXR3r171RynT59WY6ThzerqavX4dGzcuFEcAC8qKlJzrF+/Xo3p2bOnuJ5IJMzhw4fVPDZGjx4tvk/a4LYxxixatEiN0YZRgxxsT6VS4nCs7RZYGm1vSJu9I9PRtWtXcWup9957T81x6623qjGnTp1K67waIjMzU6xp48aNag6bYelLly75rqVz7XEnCMBpNEEATqMJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4LZgH0P6vP/7xj2qMzYO/peHjoHeW7tixozhY/Oabb6o5fve736kxK1asENdjsZi4o3Y6Lly4YGpqanzXJ0+erObo06ePGrN161ZxXTqHdLVu3Vp8vu7BgwfVHDY7XQ8fPlxcD+qZzZ7nn39eHNa3+bzYxHzuc5/zXUsmkyYcDqs5bM2YMUN8JvWmTZvUHD169FBjHnnkkbTOyw93ggCcRhME4DSaIACn0QQBOI0mCMBpNEEATqMJAnAaTRCA09Ka/KytrRV31v3JT36i5hg0aJAac/z4cd81m4HXdCxZssTk5OT4ri9evFjNMXXqVDXmnXfeEdeDHAKfPHmyONT7zDPPqDmkwWTPgQMHxPW6ujo1h61//vOfJiMjw3fd5rqS3mfPF77wBXE9yJqM+WRnaWlYf8SIEWqOXbt2qTELFy70XYvH4+bhhx9Wc9gaMmSIWNOQIUPUHNLO1J7nn3/ed622ttbs27dPzWEMd4IAHEcTBOA0miAAp9EEATiNJgjAaTRBAE6jCQJwGk0QgNPSGpY+dOiQuGNsaWmpmsNm2HnWrFm+a7FYzMyfP1/NYatTp04mLy/Pd3369OlqDul4z6FDh8T16upqNYetXr16iYPBX//619UcsVhMjZk9e7a4XlVVZZ588kk1j40DBw6IOzB/97vfVXNIg/6eSZMmievxeNzMmDFDzWNr/fr14vWzfPlyNcfcuXPVGKmuSCQS6LD0E088IV5/e/bsUXPY7Eqen5+f1nn54U4QgNNoggCcRhME4DSaIACn0QQBOI0mCMBpNEEATrOaE0ylUsYYYyoqKsQ4m1k3m/kfaUbNW/POqb6847XNTG3O12YDUu18vddpSF3esdo5J5NJNZdNjDbz6V0PQdSkzS3azADaxGjXg7ce1PWn/Q1t3gebDXkjkYi6FlRN2vVn8z7YbF4r5fHWrGpKWQiHwyljTKP6Fw6HbU69SdXU0LqoqWnU1FjrcrWmjFRKb5XJZNKUl5ebUCgkbnF+LaRSKRONRk1RUZHVHZifxlSTMcHURU1XX3O8/lyvyaoJAkBzxRcjAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOs/rFSFOd/5E0ppqMYabOT3OsyZjGVZfzNTXnSfCmVlND66KmplFTY63L1Zqs7gS9Zzts2LBB3Nd/06ZNaq4TJ06oMffff7/vWlVVlVm2bJn4vAkb3vFbtmwRa9Keo2GMMYlEQo15+umnxfXKykozadKkBtXlHXvixAkxz09/+lM116pVq9SYM2fOiOvRaNT06tUrkJqOHj0q5jl+/Liaq23btmrMTTfdJK5HIhFTXFwc2PX36quvis/tee6559RcN954oxpTWFjou1ZVVWXmz58fWE1r1qwRn5vy+uuvq7k+/vhjNeYf//iH71pdXZ05efKkVU1WTdC7tc3PzxffsKysLDVXZmamGpObm2t9TvVlW5PN+dr82Nv2oTANqcs7NhQKiRe99BCcdEiv8WnnVR+2NUnvoaegoECNuRY1XXl8q1atxHPPzs5Wc9l8XmweBhZUTXl5eeL1blNTUL3Epia+GAHgNJogAKfRBAE4jSYIwGk0QQBOowkCcJrViIxn8ODB4ghB37591RzHjh1TYx599FHfNZtxlHTEYjHxOQ6PP/64muPIkSNqzNKlS8V1m+cu2Jo3b544hmAz19i7d281pry8XFzXnguSjpKSErGm7t27qzkGDhwY2PkEZc+ePeKIy2c/+1k1h/acEmOM+KwNm+PTcffdd4t94s4771RznDt3To2ZMWOG71o6nyfuBAE4jSYIwGk0QQBOowkCcBpNEIDTaIIAnEYTBOA0miAAp6U1LF1WViZuUjh06FA1h7YRpzHyMGWQQ8XGGDNq1ChxsPNPf/qTmmPWrFlqzLx588T1qqoqs3//fjWPjblz54rvU6dOndQcI0aMUGO0Pd9atkzr8hJdvnxZHJYeP368mqN169aBnU9Qdu/eLf6d7rrrLjVHWVmZGlNUVOS7ZjM8n45QKCRefzZ7/D388MNqjDQgX1NTYw4cOKDmMIY7QQCOowkCcBpNEIDTaIIAnEYTBOA0miAAp9EEATiNJgjAaWlNs3br1k0cLH777bfVHHv37lVj5s6d67sm7QJdH8lkUsx58eJFNYfNDsrxeFxcr66uVnPY6tKli/g+2ZyvzQBtu3btxHWbh2zbKi0tFddtdpa2eS8fe+wxcT0ajao5gvTaa6+pMTafKWkX5pqamrTOqaHeffddNcamJmm39oqKCvWa8XAnCMBpNEEATqMJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4La1h6cOHD5uCggLf9QsXLqg5evToocZ06dLFd622ttZqd2pb06ZNE4d6S0pK1BwbNmxQY374wx+K60EPgTf0tTIzM9UYbefoIHeWfuCBB8T3SRtyNsaY3/72t2rMyZMnxfWKigo1RzpKS0vFwfYWLfT7lGnTpqkxffv29V3TBvmD9sILL6gxL7/8shozaNAg37VIJGJ9PtwJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOS2uatayszOTn5/uur127Vs1x+fJlNUbaZbmurk49Ph0XLlwQh3p79uwZyOvMnj1bXK+urjYrVqwI5LU0OTk5akzv3r3VGG3oOsgB8Ntvv93k5eX5rs+cOVPNkZWVpcbcd9994nrQO0tnZmZaDaZLMjIy1Bhp0Dzoz9T58+dNVVWV73qHDh3UHCNGjAjylETcCQJwGk0QgNNoggCcRhME4DSaIACn0QQBOI0mCMBpVnOCqVTKGKNvvlhbW6vmsomR5pa8Ne+c6ss7Xjufhr6OR5p9vHK9Ia/nHattKKmdizHG1NTUqDHa63gzdUHUJM2dGWN3vjbnoc0BxmIx61w255LO5p9+bGqXPrveWlA1aX9Dm+vP5u8i1e0db1VTykI4HE4ZYxrVv3A4bHPqTaqmhtZFTU2jpsZal6s1ZaRSeqtMJpOmvLzchEIhq+n0qymVSploNGqKioqsth7305hqMiaYuqjp6muO15/rNVk1QQBorvhiBIDTaIIAnEYTBOA0miAAp9EEATiNJgjAaVa/GGmq8z+SxlSTMczU+WmONRnTuOpyvqbmPAne1GpqaF3U1DRqaqx1uVqT1Z1gKBSyCTNf+cpX1JjWrVurMd27d/ddq66uNsuXL7c+Jz/e8eFw2BQWFvrG2fwu8+LFi2pMu3btxPVIJGK6dOnSoLq8Y8vKysSaxo0bp+ZatGiRGtOnTx9xPRKJmOLi4kBq0t6nsWPHqrneeustNWb37t3ieiwWM0OHDr1m19+BAwfUXKdPn1ZjBg8e7LsWjUZNv379rllNI0eOVHPt3btXjXn22Wd91+LxuJk9e7ZVTVZN0PbW1uZBNtIDXzy5ubmBnZN2fGFhYYObYCKRUGOk1/i086oP25qkB0t5CgoK1JimVpPNedjUbZvL5nitrlatWqm5pIefeWyawbWqyea9siE9eOs/z0nCFyMAnEYTBOA0miAAp9EEATiNJgjAaWl9TXPrrbeK3+wMGjRIzVFZWanGSF/nV1RUqMenY8+ePeI3cN/+9rfVHO+//74ao+Wx+RbaVlVVlfgt/Ouvv67msPnG+1pasGCBycnJ8V0Ph8NqjmnTpqkxo0aNEteTyaSaIx0fffSRuPX9U089pebYv3+/GjN9+nTfNe3RBenavHmz+M2tNoZkjDElJSVqzOrVq33XpEd0/CfuBAE4jSYIwGk0QQBOowkCcBpNEIDTaIIAnEYTBOA0miAAp6U1LJ2bmysOS586dUrN0a9fPzVmzpw5vmvpDEHaGD9+vLjdzoABA9QcK1asUGO+//3vi+tBDuH+7W9/E7eEshmElvZ0/G8oLS0Vdwj+1a9+pea488471ZhVq1aldV4NdfDgQXErrJtvvlnN0blzZzVG2m8xFotZDSfbKi0tFfuEzWtNnTpVjfnlL3/pu5bO54k7QQBOowkCcBpNEIDTaIIAnEYTBOA0miAAp9EEATiNJgjAaWkNS7/yyivi80RtnjtsY9euXb5riUTCHDp0KJDXMcaY9u3bi0O48+fPV3OsW7dOjXnggQfE9erqavOzn/1MzWNj//794s6+NsO1bdq0CeRcgvKvf/1LHGq/8cYb1RwXLlxQYzIzM8X1VCoV6GD7ddddJ+5sbvPA+AULFqgxHTp08F2zeX5vOo4ePSp+pqQhZ4/NDvLSDycYlgYASzRBAE6jCQJwGk0QgNNoggCcRhME4DSaIACn0QQBOC2tYenNmzeLg5Vf/OIX1RzSsLXngw8+8F2rra1Vj0/HsGHDTHZ2tu/6+PHj1Rxf+9rX1JjHH39cXI9EIoENS2dnZ4s1BTnse61069ZNHGReunSpmuPIkSNqzLhx48T1RCJhXnrpJTWPrTVr1og/MpB+OODp2LGjGjNo0CDftXg8rh6fjtzcXHFY+tKlS2qO3bt3qzG33HKL71oikTA7d+5UcxjDnSAAx9EEATiNJgjAaTRBAE6jCQJwGk0QgNNoggCcRhME4LS0hqVzcnJMTk6O7/qsWbP0F2ypv+TEiRN91+LxuNm3b5+aw9bSpUvFAe6FCxeqOWx2YdZ2LA5ygLl3797ibsVf/epXA3uta2Xr1q0mFAr5rvfv31/NMXDgQDVmy5Yt4nokEgl0WHrlypXi9bd48WI1h7TDsqdHjx6+a5FIxDz66KNqDlszZ84Uf1QxZswYNcdnPvMZNWbz5s2+a7FYjGFpALBBEwTgNJogAKfRBAE4jSYIwGk0QQBOowkCcJrVnGAqlTLG6JsvBrXhqfQ6VVVV/++c6ss7PhKJiHHRaFTNpc0A2sR459GQurxjKyoqxLiamho1l/Z3sRFkTbFYzCpOkkgk1Bit7iBquvJ47frS6jbGbk5Qqss7h6Bq8j6jfmxmYm1qkv423ppVTSkL4XA4ZYxpVP/C4bDNqTepmhpaFzU1jZoaa12u1pSRSumtMplMmvLychMKhUxGRoYWflWlUikTjUZNUVGRuIW3pjHVZEwwdVHT1dccrz/Xa7JqggDQXPHFCACn0QQBOI0mCMBpNEEATqMJAnAaTRCA02iCAJxm9bO5pjoEKWlMNRnDYLGf5liTMY2rLudras4/h2lqNTW0LmpqGjU11rpcrcnqTtB7wM1f//pX8WE3K1asUHOdOXNGjRk6dKjvWjweN3PmzBHPw4Z3fDgcFh90s2zZMjXX+vXr1ZhJkyaJ69XV1WblypUNqss79v777zdZWVm+cZs2bVJztW/fXo2RHqZjzCd3BmfPng2kpt27d5uCggLfOJv36Zvf/KYaM2TIEHE9EomY4uLiwK6/ZcuWmdzcXN+4N954Q82lbZhhjDHXX3+971oikTClpaWB1aTp1auXGmPz4Kyf//znvmuRSMR07tzZ6pysmqB3axsKhcSGIT2JziN9OD3ah+vKc6ov7/jCwkKxJukC9dj8L4TN3+bK86oP79isrCyTnZ1d7zzG2NVk+79OQdRUUFAgXtA215X0BD6PdC182nnVl3d8bm6ueL3b1GUTY3M9BFWTxmbXJZvztXmvbM6JL0YAOI0mCMBpNEEATqMJAnAaTRCA06y+HfZMmzZN/CZKGwMxxpglS5aoMWPGjPFds3lORDpefPFF8du5Y8eOqTnOnTunxmjPZ4lEIuapp55S89ioq6sTn9Fwzz33qDlKSkrUGGlkxZhPnl3Rp08fNY+Ntm3bit8Gjh49Ws2xaNEiNUYbDbJ55kc6iouLxW+tn3zySTXHCy+8oMa89dZbvmtBPRvIs379epOfn++7/qUvfUnNsW3bNjVGelaJzXNMPNwJAnAaTRCA02iCAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOS2tY+pFHHhEHO3v27Knm+Pvf/67GSEO4NTU16vHp2LZtm2nZ0v/PMHHiRDWHzT6Ks2fPFteDHAJv06aNuHXXli1b1BzDhw9XY2bOnCmuRyIRNYetgoIC8boYN26cmmPv3r1qzMmTJ8X1yspKNUc6hg0bJg6B2wz9/uEPf1Bjtm7d6rsWi8XMbbfdpuawNXbsWLGmHTt2qDmKi4vVGGlLLpvtujzcCQJwGk0QgNNoggCcRhME4DSaIACn0QQBOI0mCMBpNEEATktrWPqdd94Rn8O7c+dONcebb76pxkiDxZWVlaa0tFTNYUt7uLW2e7Ixds9IlR4UbYwxVVVVag5bs2bNEp/RO2DAADXHvHnz1BjtOb7abtrpyMrKEnc1P336tJrj0KFDasycOXPE9Wg0quZIRzKZFAeib7/9djXHkSNH1BjpAe02D29Ph7azuTaQbowxgwcPVmPYWRoAAkATBOA0miAAp9EEATiNJgjAaTRBAE6jCQJwGk0QgNPSGpbevXu3uAvz6tWr1RyLFy9WYxYtWuS7Jr1+fbRr1860aOH/34KNGzeqOSZPnqzG9OrVS1wPcmD1hhtuEHf2HTlypJpj7dq1aszZs2fF9SAHwP/85z+Lw9nDhg1Tc/zgBz9QYz766CNxPRaLqTnS0aJFC/H669Spk5pj+fLlakz//v1914LcAdzLl0qlfNfLy8vVHF27dlVjysrKfNfSGWrnThCA02iCAJxGEwTgNJogAKfRBAE4jSYIwGk0QQBOowkCcFpak8cTJkww+fn5vuvPPvusmsNm9+lXX33Vd626ulo9Ph333nuvuDN0jx491BzTp09XY4YOHSquBzmwum7dOpOXl+e7ru2ebIwxN998sxozZcoUcT0ajZolS5aoeWx8+OGHYk1Tp05Vc9TU1Kgx27dvF9eDvv7ef/99cRfwy5cvqznuuusuNSaRSNRrrT6ys7NNTk6O7/qePXvUHIMGDVJjPv/5z/uu2bzXHu4EATiNJgjAaTRBAE6jCQJwGk0QgNNoggCcRhME4DSrOUFvg8R4PC7G2cxQ2WweKuXx5n+kTRtteMdr80Q2T7K32TxUmwP01htSl3esdj42r1FXV6fGaBtXehuQBlGTdu3ZzIXZbMibkZEhrnvXZlDXn7ZJa21trZrLZsZUmgX03segatKuC5uabK4/6T336rWqKWUhHA6njDGN6l84HLY59SZVU0ProqamUVNjrcvVmjJSKb1VJpNJU15ebkKhkPpfyqstlUqZaDRqioqKxG3JNY2pJmOCqYuarr7meP25XpNVEwSA5oovRgA4jSYIwGk0QQBOowkCcBpNEIDTaIIAnEYTBOC0/wHC2xQnyI03CAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x400 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img_data(dig_train['data'].reshape((dig_train['data'].shape[0], 6, 4, 1)), figsize=(4, 4),\n",
    "              interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1725951432720,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "IUlRxKWRZz2p",
    "outputId": "47986ef0-cacb-472a-dae2-850356003f49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 5, 1, 0, 6, 0],\n",
       "       [3, 2, 3, 4, 9, 5],\n",
       "       [3, 3, 1, 6, 4, 7],\n",
       "       [5, 0, 1, 0, 2, 0],\n",
       "       [2, 6, 5, 2, 7, 2]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dig_train['target'][range(0, 30)].reshape(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1725951435412,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "lzYOx6rycIdF"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(dig_train['data'], dig_train['target'],\n",
    "                                                  test_size=0.3, random_state=4232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIRr1M4iZz2r"
   },
   "source": [
    "## Functions for Hyperparameter/Architecture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1725951441732,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "YJd7EuX0bLSG"
   },
   "outputs": [],
   "source": [
    "def create_hyperparams(n, default_lr=0.001):\n",
    "    df = pd.DataFrame(index=range(n),\n",
    "                      columns=['no_hidden_layers', 'hidden_layers', 'activation', 'dropout', 'lr', 'epochs'])\n",
    "\n",
    "    for i in range(n):\n",
    "        df.loc[i, 'lr'] = default_lr * 5.**random.uniform(-1., 1.)\n",
    "        df.loc[i, 'epochs'] = random.sample([64, 128, 256], 1)[0] # Removed 16 and 32 epochs ==> too few epochs. Also added 256\n",
    "\n",
    "        no_layers = random.randint(2, 6) # Zero and 1 hidden layers make no sense. Also increase to 6 hidden layers instead of 4\n",
    "        df.loc[i, 'no_hidden_layers'] = no_layers\n",
    "        df.loc[i, 'hidden_layers'] = [int(random.sample([32, 64, 128, 256, 512], 1)[0]) for i in range(no_layers)] # Removed 8 and 16 neurons ==> too few neurons. Also added 128, 256 and 512\n",
    "        df.loc[i, 'dropout'] = random.sample([0.2, 0.3, 0.4, 0.5], 1)[0] # Removed 0 dropout, because it is not recommended for deep networks\n",
    "        df.loc[i, 'activation'] = random.sample(['relu', 'elu'], 1)[0] # Removed sigmoid, because it does not train well for deep networks\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1725951444068,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "fFtzoyAFbaTf"
   },
   "outputs": [],
   "source": [
    "def create_network(hp, no_inputs, no_outputs, output_activation='softmax', **kwargs):\n",
    "    hidden_layers = hp['hidden_layers']\n",
    "\n",
    "    dropout = hp['dropout']\n",
    "    hidden_activation = hp['activation']\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(no_inputs, )))\n",
    "\n",
    "    for cl in hidden_layers:\n",
    "        model.add(tf.keras.layers.Dense(cl, activation=hidden_activation))\n",
    "        if dropout > 0:\n",
    "            model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(no_outputs, activation=output_activation))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=hp['lr'])\n",
    "\n",
    "    model.compile(optimizer=opt, **kwargs)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1725951447574,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "3qoRsDnIyhQ-",
    "outputId": "6c864419-8dbc-4472-d235-b97bb5781ac1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[64, 256, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[32, 128, 128, 64, 512, 256]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[512, 32, 32, 32, 128, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[64, 512, 256, 256, 128, 128]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[512, 256, 128, 512, 64, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>3</td>\n",
       "      <td>[512, 256, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00423</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>5</td>\n",
       "      <td>[512, 32, 32, 128, 256]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>5</td>\n",
       "      <td>[256, 32, 512, 32, 256]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>6</td>\n",
       "      <td>[128, 64, 64, 256, 64, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>3</td>\n",
       "      <td>[512, 128, 512]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_hidden_layers                  hidden_layers activation dropout  \\\n",
       "0                     3                  [64, 256, 32]        elu     0.4   \n",
       "1                     6   [32, 128, 128, 64, 512, 256]       relu     0.2   \n",
       "2                     6    [512, 32, 32, 32, 128, 128]       relu     0.3   \n",
       "3                     6  [64, 512, 256, 256, 128, 128]        elu     0.3   \n",
       "4                     6   [512, 256, 128, 512, 64, 64]       relu     0.2   \n",
       "...                 ...                            ...        ...     ...   \n",
       "999995                3                [512, 256, 256]        elu     0.5   \n",
       "999996                5        [512, 32, 32, 128, 256]       relu     0.4   \n",
       "999997                5        [256, 32, 512, 32, 256]       relu     0.2   \n",
       "999998                6     [128, 64, 64, 256, 64, 32]        elu     0.3   \n",
       "999999                3                [512, 128, 512]        elu     0.2   \n",
       "\n",
       "              lr epochs  \n",
       "0       0.002192     64  \n",
       "1        0.00119    256  \n",
       "2       0.000205     64  \n",
       "3       0.000284    128  \n",
       "4       0.001865    128  \n",
       "...          ...    ...  \n",
       "999995   0.00423     64  \n",
       "999996  0.004334     64  \n",
       "999997  0.001895    128  \n",
       "999998  0.001707    256  \n",
       "999999   0.00041    256  \n",
       "\n",
       "[1000000 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_hyperparams(1000) # Create 1000000 hyperparameters to search through\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1725951453572,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "3EoJWf0Obfe1"
   },
   "outputs": [],
   "source": [
    "model = create_network(df.iloc[1, :], no_inputs=24, no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1725951455805,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "2hYyghEmbiTQ",
    "outputId": "9887751a-eb2c-4a17-b3fc-53381ba39203"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m33,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,970</span> (769.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m196,970\u001b[0m (769.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196,970</span> (769.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m196,970\u001b[0m (769.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1725951459383,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "KxQzPx_-bpl9"
   },
   "outputs": [],
   "source": [
    "def find_best(df, crit='ACC'):\n",
    "    index = np.where(df[crit] == np.amax(df[crit]))[0]\n",
    "    return(df.iloc[list(index), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2zsFjuDbrDW"
   },
   "source": [
    "## Perform Model Selection and Determine Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1725951469355,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "D0tU9QQKbvb8"
   },
   "outputs": [],
   "source": [
    "random.seed(4232)\n",
    "batch_size = 32\n",
    "no_models = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1725951471887,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "0_CsQAjUbzws"
   },
   "outputs": [],
   "source": [
    "model_sel = create_hyperparams(no_models)\n",
    "model_sel['ACC'] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1725951474358,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "W7CmdoUuzMvD",
    "outputId": "3aecc9f9-9769-4bb8-9216-bc048c546691"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>[64, 64, 32, 256, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00256</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 256, 32, 32, 256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[256, 512, 32, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[32, 512, 128]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 256, 64, 128, 32, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>[128, 64, 128, 128]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>[128, 64, 256, 32, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>[256, 32, 256, 256]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>[128, 128, 64, 128, 64, 512]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>[256, 256, 32, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>[128, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>[512, 64, 512]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 512, 256, 128, 256, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>[128, 32, 512, 32]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>[64, 256, 32, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 512, 32, 128, 32, 64]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>[256, 64]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>[128, 512, 512, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>256</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>[32, 32, 64, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>[64, 128, 128, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>[64, 32, 256]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>[128, 256, 512]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>64</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>[32, 256, 32, 512, 256, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>128</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_hidden_layers                  hidden_layers activation dropout  \\\n",
       "0                 5          [64, 64, 32, 256, 32]        elu     0.2   \n",
       "1                 2                     [512, 256]        elu     0.5   \n",
       "2                 6   [256, 256, 32, 32, 256, 128]       relu     0.5   \n",
       "3                 4            [256, 512, 32, 512]       relu     0.3   \n",
       "4                 3                 [32, 512, 128]        elu     0.4   \n",
       "5                 6   [256, 256, 64, 128, 32, 256]        elu     0.2   \n",
       "6                 4            [128, 64, 128, 128]        elu     0.5   \n",
       "7                 5        [128, 64, 256, 32, 512]       relu     0.5   \n",
       "8                 4            [256, 32, 256, 256]       relu     0.5   \n",
       "9                 6   [128, 128, 64, 128, 64, 512]        elu     0.3   \n",
       "10                4             [256, 256, 32, 32]        elu     0.3   \n",
       "11                2                     [128, 512]       relu     0.3   \n",
       "12                3                 [512, 64, 512]        elu     0.2   \n",
       "13                6  [256, 512, 256, 128, 256, 64]       relu     0.2   \n",
       "14                4             [128, 32, 512, 32]        elu     0.2   \n",
       "15                4              [64, 256, 32, 64]       relu     0.4   \n",
       "16                6    [256, 512, 32, 128, 32, 64]        elu     0.2   \n",
       "17                2                      [256, 64]        elu     0.5   \n",
       "18                4           [128, 512, 512, 256]        elu     0.4   \n",
       "19                5          [32, 32, 64, 128, 64]       relu     0.2   \n",
       "20                2                     [256, 512]       relu     0.2   \n",
       "21                5        [64, 128, 128, 128, 64]       relu     0.3   \n",
       "22                3                  [64, 32, 256]       relu     0.2   \n",
       "23                3                [128, 256, 512]        elu     0.2   \n",
       "24                6   [32, 256, 32, 512, 256, 512]       relu     0.2   \n",
       "\n",
       "          lr epochs  ACC  \n",
       "0   0.000845    128 -1.0  \n",
       "1    0.00256     64 -1.0  \n",
       "2   0.000638    128 -1.0  \n",
       "3   0.001695    256 -1.0  \n",
       "4    0.00191    256 -1.0  \n",
       "5   0.001705    256 -1.0  \n",
       "6   0.004138    256 -1.0  \n",
       "7   0.000233     64 -1.0  \n",
       "8   0.000447     64 -1.0  \n",
       "9   0.000794     64 -1.0  \n",
       "10  0.000391     64 -1.0  \n",
       "11  0.000385    256 -1.0  \n",
       "12  0.000374    128 -1.0  \n",
       "13  0.002647     64 -1.0  \n",
       "14  0.001965     64 -1.0  \n",
       "15  0.001645    128 -1.0  \n",
       "16  0.000328    256 -1.0  \n",
       "17  0.000935    128 -1.0  \n",
       "18  0.000996    256 -1.0  \n",
       "19  0.001032    128 -1.0  \n",
       "20   0.00197     64 -1.0  \n",
       "21  0.000465    128 -1.0  \n",
       "22  0.000502     64 -1.0  \n",
       "23  0.002057     64 -1.0  \n",
       "24  0.000929    128 -1.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413258,
     "status": "ok",
     "timestamp": 1725951898844,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "mPYnYCYKb2Ug",
    "outputId": "fc5910bd-a6d6-46fd-b66e-affbfe56c149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 25s/step\n"
     ]
    }
   ],
   "source": [
    "pbar = tf.keras.utils.Progbar(target=no_models, stateful_metrics=[]) ## progress bar\n",
    "for i in range(no_models):\n",
    "    model = create_network(model_sel.iloc[i], no_inputs=X_train.shape[1],\n",
    "                           no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x=X_train, y=y_train,\n",
    "                        epochs=model_sel['epochs'][i],\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "\n",
    "    pred = model.predict(x=X_val, verbose=0)\n",
    "    predC = np.argmax(pred, axis=1)\n",
    "\n",
    "    model_sel.loc[i, 'ACC'] = accuracy_score(y_val, predC)\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    pbar.update(i, finalize=False)\n",
    "pbar.update(no_models, finalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1725951938286,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "jo0QXrbPnK_N",
    "outputId": "a1fb369c-0533-446e-e169-3a12a4b1073d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>64</td>\n",
       "      <td>0.952222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 512, 32, 128, 32, 64]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>256</td>\n",
       "      <td>0.948889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>[128, 512, 512, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>256</td>\n",
       "      <td>0.948889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>[128, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>256</td>\n",
       "      <td>0.947778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[256, 512, 32, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>256</td>\n",
       "      <td>0.947778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>[64, 256, 32, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>128</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 512, 256, 128, 256, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>64</td>\n",
       "      <td>0.942222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[256, 256, 64, 128, 32, 256]</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>256</td>\n",
       "      <td>0.937778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>[64, 128, 128, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>128</td>\n",
       "      <td>0.935556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>[32, 256, 32, 512, 256, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>128</td>\n",
       "      <td>0.932222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_hidden_layers                  hidden_layers activation dropout  \\\n",
       "20                2                     [256, 512]       relu     0.2   \n",
       "16                6    [256, 512, 32, 128, 32, 64]        elu     0.2   \n",
       "18                4           [128, 512, 512, 256]        elu     0.4   \n",
       "11                2                     [128, 512]       relu     0.3   \n",
       "3                 4            [256, 512, 32, 512]       relu     0.3   \n",
       "15                4              [64, 256, 32, 64]       relu     0.4   \n",
       "13                6  [256, 512, 256, 128, 256, 64]       relu     0.2   \n",
       "5                 6   [256, 256, 64, 128, 32, 256]        elu     0.2   \n",
       "21                5        [64, 128, 128, 128, 64]       relu     0.3   \n",
       "24                6   [32, 256, 32, 512, 256, 512]       relu     0.2   \n",
       "\n",
       "          lr epochs       ACC  \n",
       "20   0.00197     64  0.952222  \n",
       "16  0.000328    256  0.948889  \n",
       "18  0.000996    256  0.948889  \n",
       "11  0.000385    256  0.947778  \n",
       "3   0.001695    256  0.947778  \n",
       "15  0.001645    128  0.944444  \n",
       "13  0.002647     64  0.942222  \n",
       "5   0.001705    256  0.937778  \n",
       "21  0.000465    128  0.935556  \n",
       "24  0.000929    128  0.932222  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel.sort_values(by='ACC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1725951941761,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "oKRrMA27ciRn",
    "outputId": "874a977d-3ae1-445c-cb1a-6309d12deb79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_hidden_layers</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>[256, 512]</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>64</td>\n",
       "      <td>0.952222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_hidden_layers hidden_layers activation dropout       lr epochs       ACC\n",
       "20                2    [256, 512]       relu     0.2  0.00197     64  0.952222"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best(model_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1725951945175,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "W7C3g4pHcG67"
   },
   "outputs": [],
   "source": [
    "best_index = find_best(model_sel).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3gGoxx4cldW"
   },
   "source": [
    "## Train Model on Entire Training Set Using Best Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1725951948024,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "dHrP42SjcoGa"
   },
   "outputs": [],
   "source": [
    "model = create_network(model_sel.loc[best_index], no_inputs=X_train.shape[1],\n",
    "                       no_outputs=10, loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1725951950325,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "GevKGfVpcqUe",
    "outputId": "72696c2a-4ae3-488a-93ac-dfda5326b50d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m6,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,114</span> (559.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,114\u001b[0m (559.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,114</span> (559.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,114\u001b[0m (559.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6459,
     "status": "ok",
     "timestamp": 1725951969662,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "8SOr03A1ctap",
    "outputId": "c02a721c-e9f5-486e-c7b3-5557ec6cb564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5331 - loss: 1.5102\n",
      "Epoch 2/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8254 - loss: 0.5671\n",
      "Epoch 3/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.4473\n",
      "Epoch 4/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3956\n",
      "Epoch 5/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.3157\n",
      "Epoch 6/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2880\n",
      "Epoch 7/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2639\n",
      "Epoch 8/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2326\n",
      "Epoch 9/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2109\n",
      "Epoch 10/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.2121\n",
      "Epoch 11/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1673\n",
      "Epoch 12/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1931\n",
      "Epoch 13/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1649\n",
      "Epoch 14/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1419\n",
      "Epoch 15/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1410\n",
      "Epoch 16/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1201\n",
      "Epoch 17/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1353\n",
      "Epoch 18/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.1084\n",
      "Epoch 19/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1267\n",
      "Epoch 20/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.1153\n",
      "Epoch 21/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0943\n",
      "Epoch 22/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.0950\n",
      "Epoch 23/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1053\n",
      "Epoch 24/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0915\n",
      "Epoch 25/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1001\n",
      "Epoch 26/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9755 - loss: 0.0840\n",
      "Epoch 27/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.0872\n",
      "Epoch 28/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9668 - loss: 0.1035\n",
      "Epoch 29/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.0873\n",
      "Epoch 30/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0589\n",
      "Epoch 31/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0849\n",
      "Epoch 32/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0630\n",
      "Epoch 33/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0775\n",
      "Epoch 34/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9818 - loss: 0.0570\n",
      "Epoch 35/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0680\n",
      "Epoch 36/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0584\n",
      "Epoch 37/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0455\n",
      "Epoch 38/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.0603\n",
      "Epoch 39/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0784\n",
      "Epoch 40/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0533\n",
      "Epoch 41/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0499\n",
      "Epoch 42/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0701\n",
      "Epoch 43/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0563\n",
      "Epoch 44/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0630\n",
      "Epoch 45/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9794 - loss: 0.0560\n",
      "Epoch 46/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.0560\n",
      "Epoch 47/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0533\n",
      "Epoch 48/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0386\n",
      "Epoch 49/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0472\n",
      "Epoch 50/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0523\n",
      "Epoch 51/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0690\n",
      "Epoch 52/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0373\n",
      "Epoch 53/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0506\n",
      "Epoch 54/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9865 - loss: 0.0402\n",
      "Epoch 55/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0645\n",
      "Epoch 56/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0558\n",
      "Epoch 57/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0312\n",
      "Epoch 58/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 0.0298\n",
      "Epoch 59/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.0587\n",
      "Epoch 60/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0433\n",
      "Epoch 61/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0853\n",
      "Epoch 62/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0423\n",
      "Epoch 63/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0527\n",
      "Epoch 64/64\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=dig_train['data'], y=dig_train['target'],\n",
    "                    epochs=model_sel.loc[best_index, 'epochs'],\n",
    "                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tovQW_Llc1Fw"
   },
   "source": [
    "## Test Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1725951975129,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "5g81CNxUc2Z8",
    "outputId": "3a1f63f5-c109-45ba-8a8d-a0e6bc3df76f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion matrix (rows -> true, columns -> predicted):\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9\n",
      "0  206    2    0    0    2    0    1    1    0    0\n",
      "1    0  198    0    0    0    0    0    1    2    2\n",
      "2    0    4  179    1    0    0    1    0    0    1\n",
      "3    1    1    0  192    0    3    0    2    1    2\n",
      "4    0    3    0    0  200    0    3    1    0    1\n",
      "5    0    1    0    3    1  179    5    0    0    1\n",
      "6    1    3    0    0    3    3  193    0    1    0\n",
      "7    0    1    1    0    1    0    0  193    1    5\n",
      "8    0    6    0    5    5    1    1    1  173    1\n",
      "9    1    3    0    5    1    0    0    1    1  192\n",
      "\n",
      "\n",
      "Class 0:\n",
      "    Sensitivity (TPR):  97.170% (206 of 212)\n",
      "    Specificity (TNR):  99.833% (1789 of 1792)\n",
      "    Precision:          98.565% (206 of 209)\n",
      "    Neg. pred. value:   99.666% (1789 of 1795)\n",
      "Class 1:\n",
      "    Sensitivity (TPR):  97.537% (198 of 203)\n",
      "    Specificity (TNR):  98.667% (1777 of 1801)\n",
      "    Precision:          89.189% (198 of 222)\n",
      "    Neg. pred. value:   99.719% (1777 of 1782)\n",
      "Class 2:\n",
      "    Sensitivity (TPR):  96.237% (179 of 186)\n",
      "    Specificity (TNR):  99.945% (1817 of 1818)\n",
      "    Precision:          99.444% (179 of 180)\n",
      "    Neg. pred. value:   99.616% (1817 of 1824)\n",
      "Class 3:\n",
      "    Sensitivity (TPR):  95.050% (192 of 202)\n",
      "    Specificity (TNR):  99.223% (1788 of 1802)\n",
      "    Precision:          93.204% (192 of 206)\n",
      "    Neg. pred. value:   99.444% (1788 of 1798)\n",
      "Class 4:\n",
      "    Sensitivity (TPR):  96.154% (200 of 208)\n",
      "    Specificity (TNR):  99.276% (1783 of 1796)\n",
      "    Precision:          93.897% (200 of 213)\n",
      "    Neg. pred. value:   99.553% (1783 of 1791)\n",
      "Class 5:\n",
      "    Sensitivity (TPR):  94.211% (179 of 190)\n",
      "    Specificity (TNR):  99.614% (1807 of 1814)\n",
      "    Precision:          96.237% (179 of 186)\n",
      "    Neg. pred. value:   99.395% (1807 of 1818)\n",
      "Class 6:\n",
      "    Sensitivity (TPR):  94.608% (193 of 204)\n",
      "    Specificity (TNR):  99.389% (1789 of 1800)\n",
      "    Precision:          94.608% (193 of 204)\n",
      "    Neg. pred. value:   99.389% (1789 of 1800)\n",
      "Class 7:\n",
      "    Sensitivity (TPR):  95.545% (193 of 202)\n",
      "    Specificity (TNR):  99.612% (1795 of 1802)\n",
      "    Precision:          96.500% (193 of 200)\n",
      "    Neg. pred. value:   99.501% (1795 of 1804)\n",
      "Class 8:\n",
      "    Sensitivity (TPR):  89.637% (173 of 193)\n",
      "    Specificity (TNR):  99.669% (1805 of 1811)\n",
      "    Precision:          96.648% (173 of 179)\n",
      "    Neg. pred. value:   98.904% (1805 of 1825)\n",
      "Class 9:\n",
      "    Sensitivity (TPR):  94.118% (192 of 204)\n",
      "    Specificity (TNR):  99.278% (1787 of 1800)\n",
      "    Precision:          93.659% (192 of 205)\n",
      "    Neg. pred. value:   99.333% (1787 of 1799)\n",
      "\n",
      "Overall accuracy:   95.060% (1905 of 2004)\n",
      "Balanced accuracy:  95.026%\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(dig_test['data'])\n",
    "\n",
    "evaluate_classification_result(dig_test['target'], pred, classes=dig_test['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3800,
     "status": "ok",
     "timestamp": 1725952018810,
     "user": {
      "displayName": "Ulrich Bodenhofer",
      "userId": "07009582510819085803"
     },
     "user_tz": -120
    },
    "id": "qoGk887kBBza",
    "outputId": "d7afbc9a-927d-4a76-b024-8fce1fe3ccf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Ex3_Grimm.ipynb to html\n",
      "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
      "[NbConvertApp] Writing 341974 bytes to Ex3_Grimm.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html Ex3_Grimm.ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "NDLeIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
